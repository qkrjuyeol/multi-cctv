{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " putty에서\n",
        " uvicorn app:app --host 0.0.0.0 --port 5555 &\n",
        "\n",
        "./ngrok http 5555\n"
      ],
      "metadata": {
        "id": "TbM90Waz5qV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#분석 요청 코드(파이썬)\n",
        "import requests\n",
        "\n",
        "url = \"https://c9b5-155-230-28-29.ngrok-free.app/predict\"\n",
        "# 로컬에 있는 테스트용 비디오 파일 경로\n",
        "\n",
        "video_path = \"test_clip.mp4\"\n",
        "\n",
        "with open(video_path, \"rb\") as f:\n",
        "    files = {\"file\": (\"test_clip\", f, \"application/octet-stream\")}\n",
        "    response = requests.post(url, files=files)\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "PHt9XSQ85Geo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1524c47a-01e2-47d2-89db-e7646e47c808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{'class': 'burglary', 'confidence': 0.9146443009376526, 'detected_objects': ['person']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "소요시간\n",
        "\n",
        "Preprocess: 4.6ms  \n",
        "Inference: 4.1ms  \n",
        "Postprocess: 110.0ms"
      ],
      "metadata": {
        "id": "EOHfA_MREY_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#객체탐지 후 행동분석 서버 코드\n",
        "#app2.py\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import video as video_models\n",
        "from torchvision.io import read_video\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "from pydantic import BaseModel\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 클래스 설정\n",
        "classes = ['normal', 'trespass', 'fight', 'dump', 'burglary', 'vandalism']\n",
        "allowed_objects = [\n",
        "    #사람,차량\n",
        "    'person', 'car', 'bus', 'truck', 'motorbike', 'bicycle', 'train',\n",
        "    # 동물\n",
        "    'dog', 'cat', 'bird', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe'\n",
        "]\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "# 객체탐지 모델\n",
        "yolo_model = YOLO('yolov8n.pt')\n",
        "# 이상행동 분류 모델\n",
        "def build_model(num_classes=6):\n",
        "    model = video_models.r3d_18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = build_model(num_classes=len(classes))\n",
        "model.load_state_dict(torch.load(\"anomaly_detection_model.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 비디오 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.Normalize([0.43216, 0.394666, 0.37645],\n",
        "                         [0.22803, 0.22145, 0.216989])\n",
        "])\n",
        "\n",
        "# FastAPI 앱\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        contents = await file.read()\n",
        "        video_bytes = io.BytesIO(contents)\n",
        "\n",
        "        # 임시 저장\n",
        "        with open(\"temp.mp4\", \"wb\") as f:\n",
        "            f.write(video_bytes.read())\n",
        "\n",
        "        # 비디오 로드\n",
        "        video, _, _ = read_video(\"temp.mp4\", pts_unit=\"sec\")  # (T, H, W, C)\n",
        "        if video.shape[0] == 0:\n",
        "            return JSONResponse({\"error\": \"비디오 프레임이 없습니다.\"}, status_code=400)\n",
        "\n",
        "        # 첫 프레임을 YOLO 추론\n",
        "        first_frame = video[0].numpy()  # (H, W, C)\n",
        "        first_frame_bgr = cv2.cvtColor(first_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        results = yolo_model.predict(source=first_frame_bgr, conf=0.4, classes=None, device=0 if torch.cuda.is_available() else \"cpu\")\n",
        "        names = results[0].names\n",
        "        detected = results[0].boxes.cls.tolist()\n",
        "        detected_labels = [names[int(cls)] for cls in detected]\n",
        "\n",
        "        # 객체 감지 여부 확인\n",
        "        relevant_labels = [label for label in detected_labels if label in allowed_objects]\n",
        "        if not relevant_labels:\n",
        "            return JSONResponse({\n",
        "                \"class\": \"normal\",\n",
        "                \"confidence\": 1.0,\n",
        "                \"detected_objects\": []\n",
        "            })\n",
        "\n",
        "        # 이상행동 분석\n",
        "        video = video.permute(0, 3, 1, 2).float() / 255.0  # (T, C, H, W)\n",
        "        clip_len = 60\n",
        "        if video.shape[0] > clip_len:\n",
        "            video = video[:clip_len]\n",
        "        elif video.shape[0] < clip_len:\n",
        "            pad = clip_len - video.shape[0]\n",
        "            video = torch.cat([video, video[-1:].repeat(pad, 1, 1, 1)], dim=0)\n",
        "\n",
        "        video = transform(video)\n",
        "        video = video.permute(1, 0, 2, 3).unsqueeze(0).to(device)  # (1, C, T, H, W)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(video)\n",
        "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "            pred = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return JSONResponse({\n",
        "            \"class\": classes[pred],\n",
        "            \"confidence\": float(probs[0][pred]),\n",
        "            \"detected_objects\": relevant_labels\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return JSONResponse({\"error\": str(e)}, status_code=500)\n"
      ],
      "metadata": {
        "id": "DNwB17orMVG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이상행동 분석 서버코드\n",
        "#app.py\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import video as video_models\n",
        "from torchvision.io import read_video\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "# 클래스 [보통, 침입, 싸움, 투기, 도둑질, 기물파손]\n",
        "classes = ['normal', 'trespass', 'fight', 'dump', 'burglary', 'vandalism']\n",
        "\n",
        "# GPU 우선\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 생성\n",
        "def build_model(num_classes=6):\n",
        "    model = video_models.r3d_18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# 모델 로드\n",
        "model = build_model(num_classes=len(classes))\n",
        "model.load_state_dict(torch.load(\"anomaly_detection_model.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.Normalize([0.43216, 0.394666, 0.37645],\n",
        "                         [0.22803, 0.22145, 0.216989])\n",
        "])\n",
        "\n",
        "# FastAPI 초기화\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        # 파일 로드\n",
        "        contents = await file.read()\n",
        "        video_bytes = io.BytesIO(contents)\n",
        "\n",
        "        # 임시 파일로 저장\n",
        "        with open(\"temp.mp4\", \"wb\") as f:\n",
        "            f.write(video_bytes.read())\n",
        "\n",
        "        # 임시 파일 로드\n",
        "        video, _, _ = read_video(\"temp.mp4\", pts_unit=\"sec\")  # (T, H, W, C)\n",
        "        video = video.permute(0, 3, 1, 2).float() / 255.0      # (T, C, H, W)\n",
        "\n",
        "        clip_len = 60\n",
        "        if video.shape[0] > clip_len:\n",
        "            video = video[:clip_len]\n",
        "        elif video.shape[0] < clip_len:\n",
        "            pad = clip_len - video.shape[0]\n",
        "            video = torch.cat([video, video[-1:].repeat(pad, 1, 1, 1)], dim=0)\n",
        "\n",
        "        video = transform(video)\n",
        "        video = video.permute(1, 0, 2, 3).unsqueeze(0).to(device)  # (1, C, T, H, W)\n",
        "\n",
        "        # 추론\n",
        "        with torch.no_grad():\n",
        "            logits = model(video)\n",
        "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "            pred = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return JSONResponse({\"class\": classes[pred], \"confidence\": float(probs[0][pred])})\n",
        "\n",
        "    except Exception as e:\n",
        "        return JSONResponse({\"error\": str(e)}, status_code=500)"
      ],
      "metadata": {
        "id": "wjfgvNgJ-N3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ai 모델 코드\n",
        "#ai.py\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_video\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torchvision.models import video as video_models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class VideoClipDataset(Dataset):\n",
        "    def __init__(self, root_dir, classes, clip_len=60):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = classes\n",
        "        self.clip_len = clip_len\n",
        "        self.samples = []\n",
        "        for label_idx, label in enumerate(classes):\n",
        "            class_dir = os.path.join(root_dir, label)\n",
        "            for fname in os.listdir(class_dir):\n",
        "                if fname.endswith(\".mp4\"):\n",
        "                    self.samples.append((os.path.join(class_dir, fname), label_idx))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((112, 112)),\n",
        "            transforms.Normalize([0.43216, 0.394666, 0.37645],\n",
        "                                 [0.22803, 0.22145, 0.216989])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path, label = self.samples[idx]\n",
        "        video, _, _ = read_video(video_path, pts_unit='sec')  # (T, H, W, C)\n",
        "\n",
        "        video = video.permute(0, 3, 1, 2).float() / 255.0  # (T, C, H, W)\n",
        "\n",
        "        if video.shape[0] > self.clip_len:\n",
        "            video = video[:self.clip_len]\n",
        "        elif video.shape[0] < self.clip_len:\n",
        "            pad = self.clip_len - video.shape[0]\n",
        "            video = torch.cat([video, video[-1:].repeat(pad, 1, 1, 1)], dim=0)\n",
        "\n",
        "        if self.transform:\n",
        "            video = self.transform(video)\n",
        "\n",
        "        video = video.permute(1, 0, 2, 3)  # (C, T, H, W) ← 여기 추가!\n",
        "\n",
        "        return video, label\n",
        "\n",
        "def build_model(num_classes=6):\n",
        "    model = video_models.r3d_18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def train(model, dataloader, device, epochs=5):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, total_acc = 0, 0\n",
        "        for x, y in tqdm(dataloader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            acc = (preds == y).float().mean()\n",
        "            total_loss += loss.item()\n",
        "            total_acc += acc.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}: Loss {total_loss/len(dataloader):.4f}, Acc {total_acc/len(dataloader):.4f}\")\n",
        "\n",
        "classes = ['normal', 'trespass', 'fight', 'dump', 'burglary', 'vandalism']\n",
        "clip_output_dir = r\"D:\\clips\"\n",
        "\n",
        "dataset = VideoClipDataset(clip_output_dir, classes)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = build_model(num_classes=len(classes))\n",
        "train(model, dataloader, device, epochs=10)\n"
      ],
      "metadata": {
        "id": "MzGovknFntpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Epoch 1]  Loss: 0.667  Accuracy: 74.9%\n",
        "\n",
        "\n",
        "[Epoch10]  Loss: 0.360  Accuracy: 83.9%"
      ],
      "metadata": {
        "id": "ByPOU7bYFFK9"
      }
    }
  ]
}